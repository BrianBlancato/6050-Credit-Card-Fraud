{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\brian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountNumber</th>\n",
       "      <th>customerId</th>\n",
       "      <th>creditLimit</th>\n",
       "      <th>availableMoney</th>\n",
       "      <th>transactionDateTime</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>merchantName</th>\n",
       "      <th>acqCountry</th>\n",
       "      <th>merchantCountryCode</th>\n",
       "      <th>posEntryMode</th>\n",
       "      <th>...</th>\n",
       "      <th>echoBuffer</th>\n",
       "      <th>currentBalance</th>\n",
       "      <th>merchantCity</th>\n",
       "      <th>merchantState</th>\n",
       "      <th>merchantZip</th>\n",
       "      <th>cardPresent</th>\n",
       "      <th>posOnPremises</th>\n",
       "      <th>recurringAuthInd</th>\n",
       "      <th>expirationDateKeyInMatch</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>737265056</td>\n",
       "      <td>737265056</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2016-08-13T14:27:32</td>\n",
       "      <td>98.55</td>\n",
       "      <td>Uber</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>737265056</td>\n",
       "      <td>737265056</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2016-10-11T05:05:54</td>\n",
       "      <td>74.51</td>\n",
       "      <td>AMC #191138</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>09</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>737265056</td>\n",
       "      <td>737265056</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2016-11-08T09:18:39</td>\n",
       "      <td>7.47</td>\n",
       "      <td>Play Store</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>09</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>737265056</td>\n",
       "      <td>737265056</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2016-12-10T02:14:50</td>\n",
       "      <td>7.47</td>\n",
       "      <td>Play Store</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>09</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>830329091</td>\n",
       "      <td>830329091</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2016-03-24T21:04:46</td>\n",
       "      <td>71.18</td>\n",
       "      <td>Tim Hortons #947751</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountNumber  customerId  creditLimit  availableMoney  \\\n",
       "0      737265056   737265056         5000          5000.0   \n",
       "1      737265056   737265056         5000          5000.0   \n",
       "2      737265056   737265056         5000          5000.0   \n",
       "3      737265056   737265056         5000          5000.0   \n",
       "4      830329091   830329091         5000          5000.0   \n",
       "\n",
       "   transactionDateTime  transactionAmount         merchantName acqCountry  \\\n",
       "0  2016-08-13T14:27:32              98.55                 Uber         US   \n",
       "1  2016-10-11T05:05:54              74.51          AMC #191138         US   \n",
       "2  2016-11-08T09:18:39               7.47           Play Store         US   \n",
       "3  2016-12-10T02:14:50               7.47           Play Store         US   \n",
       "4  2016-03-24T21:04:46              71.18  Tim Hortons #947751         US   \n",
       "\n",
       "  merchantCountryCode posEntryMode  ... echoBuffer currentBalance  \\\n",
       "0                  US           02  ...                       0.0   \n",
       "1                  US           09  ...                       0.0   \n",
       "2                  US           09  ...                       0.0   \n",
       "3                  US           09  ...                       0.0   \n",
       "4                  US           02  ...                       0.0   \n",
       "\n",
       "  merchantCity merchantState merchantZip  cardPresent  posOnPremises  \\\n",
       "0                                               False                  \n",
       "1                                                True                  \n",
       "2                                               False                  \n",
       "3                                               False                  \n",
       "4                                                True                  \n",
       "\n",
       "   recurringAuthInd expirationDateKeyInMatch isFraud  \n",
       "0                                      False   False  \n",
       "1                                      False   False  \n",
       "2                                      False   False  \n",
       "3                                      False   False  \n",
       "4                                      False   False  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('transactions.txt', lines=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing white space with nan\n",
    "\n",
    "df = df.replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty columns that were removed:\n",
      "['echoBuffer', 'merchantCity', 'merchantState', 'merchantZip', 'posOnPremises', 'recurringAuthInd']\n"
     ]
    }
   ],
   "source": [
    "# Checking which columns are empty and removing\n",
    "\n",
    "nan_col = df.columns[df.isna().all()].tolist()\n",
    "df.drop(columns=nan_col, inplace=True)\n",
    "\n",
    "print(\"Empty columns that were removed:\")\n",
    "print(nan_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Account Number and Customer Id columns appear to be equal\n",
    "\n",
    "df['accountNumber'].equals(df['customerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing customerId as it is a duplicate of accountNumber\n",
    "\n",
    "df.drop(columns=['customerId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping merchantName as merchantCategory will be used\n",
    "df.drop(columns=['merchantName'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to remove remaining unneeded columns\n",
    "#df.drop(columns=['cardCVV'], inplace=True)\n",
    "#df.drop(columns=['enteredCVV'], inplace=True)\n",
    "df.drop(columns=['cardLast4Digits'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NaN with purchase to keep data\n",
    "\n",
    "df['transactionType'] = df['transactionType'].fillna('PURCHASE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total amount of rows with NaN values\n",
    "df.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all rows with NaN value\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing transactionDatetime. All transactions occurred in 2016, year is unneeded.\n",
    "\n",
    "df['transactionDateTime'] = pd.to_datetime(df['transactionDateTime'])\n",
    "df['Month'] = df['transactionDateTime'].dt.month\n",
    "df['day'] = df['transactionDateTime'].dt.day\n",
    "df['hour'] = df['transactionDateTime'].dt.hour\n",
    "df['minute'] = df['transactionDateTime'].dt.minute\n",
    "\n",
    "# Cyclic encoding for hour and minute\n",
    "df['hourSin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hourCos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['minuteSin'] = np.sin(2 * np.pi * df['minute'] / 24)\n",
    "df['minuteCos'] = np.cos(2 * np.pi * df['minute'] / 24)\n",
    "\n",
    "# Do not need columns\n",
    "df.drop(columns=['transactionDateTime'], inplace=True)\n",
    "df.drop(columns=['hour'], inplace=True)\n",
    "df.drop(columns=['minute'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformatting other date columns\n",
    "\n",
    "df['expYear'] = pd.to_datetime(df['currentExpDate']).dt.year\n",
    "df['expMonth'] = pd.to_datetime(df['currentExpDate']).dt.month\n",
    "\n",
    "df['accountOpenYear'] = pd.to_datetime(df['accountOpenDate']).dt.year\n",
    "df['accountOpenMonth'] = pd.to_datetime(df['accountOpenDate']).dt.month\n",
    "df['accountOpenDay'] = pd.to_datetime(df['accountOpenDate']).dt.day\n",
    "\n",
    "df['lastAddressChangeYear'] = pd.to_datetime(df['dateOfLastAddressChange']).dt.year\n",
    "df['lastAddressChangeMonth'] = pd.to_datetime(df['dateOfLastAddressChange']).dt.month\n",
    "df['lastAddressChangeDay'] = pd.to_datetime(df['dateOfLastAddressChange']).dt.day\n",
    "\n",
    "# removing unneeded columns\n",
    "df.drop(columns=['currentExpDate'], inplace=True)\n",
    "df.drop(columns=['accountOpenDate'], inplace=True)\n",
    "df.drop(columns=['dateOfLastAddressChange'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns that need to be endocded\n",
    "\n",
    "columns_to_encode = ['acqCountry', 'merchantCountryCode', 'posEntryMode', 'posConditionCode', 'transactionType', 'merchantCategoryCode']\n",
    "df = pd.get_dummies(df, columns=columns_to_encode, prefix=columns_to_encode)\n",
    "\n",
    "# Convert boolean columns to integers\n",
    "df['cardPresent'] = df['cardPresent'].astype(int)\n",
    "df['expirationDateKeyInMatch'] = df['expirationDateKeyInMatch'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 777360 entries, 0 to 786362\n",
      "Data columns (total 62 columns):\n",
      " #   Column                                     Non-Null Count   Dtype  \n",
      "---  ------                                     --------------   -----  \n",
      " 0   accountNumber                              777360 non-null  int64  \n",
      " 1   creditLimit                                777360 non-null  int64  \n",
      " 2   availableMoney                             777360 non-null  float64\n",
      " 3   transactionAmount                          777360 non-null  float64\n",
      " 4   cardCVV                                    777360 non-null  int64  \n",
      " 5   enteredCVV                                 777360 non-null  int64  \n",
      " 6   currentBalance                             777360 non-null  float64\n",
      " 7   cardPresent                                777360 non-null  int32  \n",
      " 8   expirationDateKeyInMatch                   777360 non-null  int32  \n",
      " 9   isFraud                                    777360 non-null  bool   \n",
      " 10  Month                                      777360 non-null  int64  \n",
      " 11  day                                        777360 non-null  int64  \n",
      " 12  hourSin                                    777360 non-null  float64\n",
      " 13  hourCos                                    777360 non-null  float64\n",
      " 14  minuteSin                                  777360 non-null  float64\n",
      " 15  minuteCos                                  777360 non-null  float64\n",
      " 16  expYear                                    777360 non-null  int64  \n",
      " 17  expMonth                                   777360 non-null  int64  \n",
      " 18  accountOpenYear                            777360 non-null  int64  \n",
      " 19  accountOpenMonth                           777360 non-null  int64  \n",
      " 20  accountOpenDay                             777360 non-null  int64  \n",
      " 21  lastAddressChangeYear                      777360 non-null  int64  \n",
      " 22  lastAddressChangeMonth                     777360 non-null  int64  \n",
      " 23  lastAddressChangeDay                       777360 non-null  int64  \n",
      " 24  acqCountry_CAN                             777360 non-null  uint8  \n",
      " 25  acqCountry_MEX                             777360 non-null  uint8  \n",
      " 26  acqCountry_PR                              777360 non-null  uint8  \n",
      " 27  acqCountry_US                              777360 non-null  uint8  \n",
      " 28  merchantCountryCode_CAN                    777360 non-null  uint8  \n",
      " 29  merchantCountryCode_MEX                    777360 non-null  uint8  \n",
      " 30  merchantCountryCode_PR                     777360 non-null  uint8  \n",
      " 31  merchantCountryCode_US                     777360 non-null  uint8  \n",
      " 32  posEntryMode_02                            777360 non-null  uint8  \n",
      " 33  posEntryMode_05                            777360 non-null  uint8  \n",
      " 34  posEntryMode_09                            777360 non-null  uint8  \n",
      " 35  posEntryMode_80                            777360 non-null  uint8  \n",
      " 36  posEntryMode_90                            777360 non-null  uint8  \n",
      " 37  posConditionCode_01                        777360 non-null  uint8  \n",
      " 38  posConditionCode_08                        777360 non-null  uint8  \n",
      " 39  posConditionCode_99                        777360 non-null  uint8  \n",
      " 40  transactionType_ADDRESS_VERIFICATION       777360 non-null  uint8  \n",
      " 41  transactionType_PURCHASE                   777360 non-null  uint8  \n",
      " 42  transactionType_REVERSAL                   777360 non-null  uint8  \n",
      " 43  merchantCategoryCode_airline               777360 non-null  uint8  \n",
      " 44  merchantCategoryCode_auto                  777360 non-null  uint8  \n",
      " 45  merchantCategoryCode_cable/phone           777360 non-null  uint8  \n",
      " 46  merchantCategoryCode_entertainment         777360 non-null  uint8  \n",
      " 47  merchantCategoryCode_fastfood              777360 non-null  uint8  \n",
      " 48  merchantCategoryCode_food                  777360 non-null  uint8  \n",
      " 49  merchantCategoryCode_food_delivery         777360 non-null  uint8  \n",
      " 50  merchantCategoryCode_fuel                  777360 non-null  uint8  \n",
      " 51  merchantCategoryCode_furniture             777360 non-null  uint8  \n",
      " 52  merchantCategoryCode_gym                   777360 non-null  uint8  \n",
      " 53  merchantCategoryCode_health                777360 non-null  uint8  \n",
      " 54  merchantCategoryCode_hotels                777360 non-null  uint8  \n",
      " 55  merchantCategoryCode_mobileapps            777360 non-null  uint8  \n",
      " 56  merchantCategoryCode_online_gifts          777360 non-null  uint8  \n",
      " 57  merchantCategoryCode_online_retail         777360 non-null  uint8  \n",
      " 58  merchantCategoryCode_online_subscriptions  777360 non-null  uint8  \n",
      " 59  merchantCategoryCode_personal care         777360 non-null  uint8  \n",
      " 60  merchantCategoryCode_rideshare             777360 non-null  uint8  \n",
      " 61  merchantCategoryCode_subscriptions         777360 non-null  uint8  \n",
      "dtypes: bool(1), float64(7), int32(2), int64(14), uint8(38)\n",
      "memory usage: 165.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaking apart features and labels\n",
    "\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df['isFraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset into train, test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = df.drop('isFraud', axis = 1)\n",
    "Y = df['isFraud']\n",
    "\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.7, random_state=333, stratify=Y)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=333, stratify=y_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize/normalize your numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#use DataFrame.select_dtypes() to select float64 or int64 feature types automatically.\n",
    "numerical_features = features.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_columns = numerical_features.columns # Get a list of the column names\n",
    "ct = ColumnTransformer([(\"only numeric\", StandardScaler(), numerical_columns)], remainder='passthrough')\n",
    "\n",
    "#Fit your instance ct of ColumnTransformer to the training data and at the same time transform it by using the ColumnTransformer.fit_transform()\n",
    "x_train_scaled = ct.fit_transform(x_train)\n",
    "x_test_scaled = ct.fit_transform(x_test) #Transform your test data instance features_test\n",
    "x_val_scaled = ct.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\brian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\brian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Recall()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\brian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "7288/7288 [==============================] - 13s 2ms/step - loss: 0.0754 - binary_accuracy: 0.9844 - recall: 2.7824e-04 - val_loss: 0.0740 - val_binary_accuracy: 0.9846 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "7288/7288 [==============================] - 11s 2ms/step - loss: 0.0726 - binary_accuracy: 0.9846 - recall: 0.0000e+00 - val_loss: 0.0738 - val_binary_accuracy: 0.9846 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "7288/7288 [==============================] - 11s 2ms/step - loss: 0.0715 - binary_accuracy: 0.9846 - recall: 0.0000e+00 - val_loss: 0.0718 - val_binary_accuracy: 0.9846 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0707 - binary_accuracy: 0.9846 - recall: 0.0000e+00 - val_loss: 0.0727 - val_binary_accuracy: 0.9846 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0699 - binary_accuracy: 0.9846 - recall: 0.0000e+00 - val_loss: 0.0712 - val_binary_accuracy: 0.9846 - val_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0693 - binary_accuracy: 0.9846 - recall: 2.7824e-04 - val_loss: 0.0715 - val_binary_accuracy: 0.9846 - val_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0688 - binary_accuracy: 0.9846 - recall: 5.5648e-04 - val_loss: 0.0725 - val_binary_accuracy: 0.9846 - val_recall: 0.0000e+00\n",
      "Epoch 8/10\n",
      "7288/7288 [==============================] - 13s 2ms/step - loss: 0.0683 - binary_accuracy: 0.9846 - recall: 0.0011 - val_loss: 0.0718 - val_binary_accuracy: 0.9845 - val_recall: 4.7699e-04\n",
      "Epoch 9/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0679 - binary_accuracy: 0.9846 - recall: 8.3472e-04 - val_loss: 0.0719 - val_binary_accuracy: 0.9845 - val_recall: 0.0017\n",
      "Epoch 10/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0673 - binary_accuracy: 0.9846 - recall: 0.0039 - val_loss: 0.0719 - val_binary_accuracy: 0.9845 - val_recall: 9.5397e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, \n",
    "                    validation_data=(x_val_scaled, y_val),\n",
    "                    epochs=10,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8503/8503 [==============================] - 7s 771us/step - loss: 0.0723 - binary_accuracy: 0.9845 - recall: 4.7699e-04\n",
      "Test Accuracy: [0.072347491979599, 0.9845043420791626, 0.00047698544221930206]\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8503/8503 [==============================] - 6s 665us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      1.00      0.99    267883\n",
      "        True       0.07      0.00      0.00      4193\n",
      "\n",
      "    accuracy                           0.98    272076\n",
      "   macro avg       0.53      0.50      0.50    272076\n",
      "weighted avg       0.97      0.98      0.98    272076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed report of model to look at all metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5001918305637593\n",
      "Confusion Matrix:\n",
      "[[267858     25]\n",
      " [  4191      2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix\n",
    "\n",
    "# ROC Curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "# Confusion Matrix\n",
    "threshold = 0.5 \n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Print metrics\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying SMOTE to address the class imbalance\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=333)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize/normalize your numerical features\n",
    "\n",
    "#use DataFrame.select_dtypes() to select float64 or int64 feature types automatically.\n",
    "numerical_features = features.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_columns = numerical_features.columns # Get a list of the column names\n",
    "ct = ColumnTransformer([(\"only numeric\", StandardScaler(), numerical_columns)], remainder='passthrough')\n",
    "\n",
    "#Fit your instance ct of ColumnTransformer to the training data and at the same time transform it by using the ColumnTransformer.fit_transform()\n",
    "x_train_scaled = ct.fit_transform(x_train_resampled)\n",
    "x_test_scaled = ct.fit_transform(x_test) #Transform your test data instance features_test\n",
    "x_val_scaled = ct.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Recall()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14351/14351 [==============================] - 20s 1ms/step - loss: 0.1257 - binary_accuracy: 0.9522 - recall_1: 0.9335 - val_loss: 0.1465 - val_binary_accuracy: 0.9515 - val_recall_1: 0.1340\n",
      "Epoch 2/10\n",
      "14351/14351 [==============================] - 19s 1ms/step - loss: 0.0786 - binary_accuracy: 0.9733 - recall_1: 0.9599 - val_loss: 0.2082 - val_binary_accuracy: 0.9221 - val_recall_1: 0.2392\n",
      "Epoch 3/10\n",
      "14351/14351 [==============================] - 18s 1ms/step - loss: 0.0704 - binary_accuracy: 0.9768 - recall_1: 0.9644 - val_loss: 0.2594 - val_binary_accuracy: 0.8985 - val_recall_1: 0.2678\n",
      "Epoch 4/10\n",
      "14351/14351 [==============================] - 19s 1ms/step - loss: 0.0659 - binary_accuracy: 0.9786 - recall_1: 0.9671 - val_loss: 0.2676 - val_binary_accuracy: 0.8953 - val_recall_1: 0.2650\n",
      "Epoch 5/10\n",
      "14351/14351 [==============================] - 19s 1ms/step - loss: 0.0627 - binary_accuracy: 0.9799 - recall_1: 0.9690 - val_loss: 0.4314 - val_binary_accuracy: 0.8306 - val_recall_1: 0.3539\n",
      "Epoch 6/10\n",
      "14351/14351 [==============================] - 19s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9807 - recall_1: 0.9703 - val_loss: 0.2542 - val_binary_accuracy: 0.9060 - val_recall_1: 0.2580\n",
      "Epoch 7/10\n",
      "14351/14351 [==============================] - 20s 1ms/step - loss: 0.0582 - binary_accuracy: 0.9815 - recall_1: 0.9714 - val_loss: 0.4272 - val_binary_accuracy: 0.8431 - val_recall_1: 0.3694\n",
      "Epoch 8/10\n",
      "14351/14351 [==============================] - 19s 1ms/step - loss: 0.0568 - binary_accuracy: 0.9821 - recall_1: 0.9723 - val_loss: 0.4112 - val_binary_accuracy: 0.8425 - val_recall_1: 0.3260\n",
      "Epoch 9/10\n",
      "14351/14351 [==============================] - 19s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9827 - recall_1: 0.9732 - val_loss: 0.3321 - val_binary_accuracy: 0.8766 - val_recall_1: 0.3029\n",
      "Epoch 10/10\n",
      "14351/14351 [==============================] - 18s 1ms/step - loss: 0.0542 - binary_accuracy: 0.9830 - recall_1: 0.9739 - val_loss: 0.3586 - val_binary_accuracy: 0.8689 - val_recall_1: 0.3031\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train_resampled, \n",
    "                    validation_data=(x_val_scaled, y_val),\n",
    "                    epochs=10,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8503/8503 [==============================] - 6s 729us/step - loss: 0.3561 - binary_accuracy: 0.8693 - recall_1: 0.3012\n",
      "Test Accuracy: [0.35609349608421326, 0.8692755103111267, 0.3012163043022156]\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8503/8503 [==============================] - 5s 627us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.88      0.93    267883\n",
      "        True       0.04      0.30      0.07      4193\n",
      "\n",
      "    accuracy                           0.87    272076\n",
      "   macro avg       0.51      0.59      0.50    272076\n",
      "weighted avg       0.97      0.87      0.92    272076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5896916369259131\n",
      "Confusion Matrix:\n",
      "[[235246  32637]\n",
      " [  2930   1263]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ROC Curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "# Confusion Matrix\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Print metrics\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "Using precision as a metric and no SMOTE since it did not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize/normalize your numerical features\n",
    "\n",
    "#use DataFrame.select_dtypes() to select float64 or int64 feature types automatically.\n",
    "numerical_features = features.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_columns = numerical_features.columns # Get a list of the column names\n",
    "ct = ColumnTransformer([(\"only numeric\", StandardScaler(), numerical_columns)], remainder='passthrough')\n",
    "\n",
    "#Fit your instance ct of ColumnTransformer to the training data and at the same time transform it by using the ColumnTransformer.fit_transform()\n",
    "x_train_scaled = ct.fit_transform(x_train)\n",
    "x_test_scaled = ct.fit_transform(x_test) #Transform your test data instance features_test\n",
    "x_val_scaled = ct.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7288/7288 [==============================] - 13s 2ms/step - loss: 0.0748 - binary_accuracy: 0.9846 - recall_2: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.0733 - val_binary_accuracy: 0.9846 - val_recall_2: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 2/10\n",
      "7288/7288 [==============================] - 13s 2ms/step - loss: 0.0727 - binary_accuracy: 0.9846 - recall_2: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.0723 - val_binary_accuracy: 0.9846 - val_recall_2: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 3/10\n",
      "7288/7288 [==============================] - 13s 2ms/step - loss: 0.0716 - binary_accuracy: 0.9846 - recall_2: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.0727 - val_binary_accuracy: 0.9846 - val_recall_2: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 4/10\n",
      "7288/7288 [==============================] - 13s 2ms/step - loss: 0.0708 - binary_accuracy: 0.9846 - recall_2: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.0719 - val_binary_accuracy: 0.9846 - val_recall_2: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 5/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0702 - binary_accuracy: 0.9846 - recall_2: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.0724 - val_binary_accuracy: 0.9846 - val_recall_2: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 6/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0695 - binary_accuracy: 0.9846 - recall_2: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.0716 - val_binary_accuracy: 0.9846 - val_recall_2: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 7/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0690 - binary_accuracy: 0.9846 - recall_2: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.0721 - val_binary_accuracy: 0.9846 - val_recall_2: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 8/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0685 - binary_accuracy: 0.9846 - recall_2: 2.7824e-04 - precision: 1.0000 - val_loss: 0.0713 - val_binary_accuracy: 0.9846 - val_recall_2: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 9/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0680 - binary_accuracy: 0.9846 - recall_2: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.0717 - val_binary_accuracy: 0.9846 - val_recall_2: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 10/10\n",
      "7288/7288 [==============================] - 12s 2ms/step - loss: 0.0674 - binary_accuracy: 0.9846 - recall_2: 8.3472e-04 - precision: 0.6000 - val_loss: 0.0719 - val_binary_accuracy: 0.9846 - val_recall_2: 0.0000e+00 - val_precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, \n",
    "                    validation_data=(x_val_scaled, y_val),\n",
    "                    epochs=10,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8503/8503 [==============================] - 6s 751us/step - loss: 0.0720 - binary_accuracy: 0.9846 - recall_2: 0.0000e+00 - precision: 0.0000e+00\n",
      "Test Accuracy: [0.07198310643434525, 0.9845815300941467, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8503/8503 [==============================] - 6s 668us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      1.00      0.99    267883\n",
      "        True       0.00      0.00      0.00      4193\n",
      "\n",
      "    accuracy                           0.98    272076\n",
      "   macro avg       0.49      0.50      0.50    272076\n",
      "weighted avg       0.97      0.98      0.98    272076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed report of model to look at all metrics\n",
    "\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.499996267027023\n",
      "Confusion Matrix:\n",
      "[[267881      2]\n",
      " [  4193      0]]\n"
     ]
    }
   ],
   "source": [
    "# ROC Curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "# Confusion Matrix\n",
    "threshold = 0.5 \n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Print metrics\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4\n",
    "Model architecture changes.  \n",
    "Adding two more hidden layers.  \n",
    "Adding dropout layers  \n",
    "Adding regularization to hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.1), input_shape=(x_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.1)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.1)),\n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.1)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7288/7288 [==============================] - 18s 2ms/step - loss: 0.3259 - binary_accuracy: 0.9814 - recall_3: 0.0031 - precision_1: 0.0143 - val_loss: 0.0798 - val_binary_accuracy: 0.9846 - val_recall_3: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 2/10\n",
      "7288/7288 [==============================] - 16s 2ms/step - loss: 0.0827 - binary_accuracy: 0.9846 - recall_3: 0.0000e+00 - precision_1: 0.0000e+00 - val_loss: 0.0797 - val_binary_accuracy: 0.9846 - val_recall_3: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 3/10\n",
      "7288/7288 [==============================] - 16s 2ms/step - loss: 0.0804 - binary_accuracy: 0.9846 - recall_3: 0.0000e+00 - precision_1: 0.0000e+00 - val_loss: 0.0797 - val_binary_accuracy: 0.9846 - val_recall_3: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 4/10\n",
      "7288/7288 [==============================] - 18s 2ms/step - loss: 0.0799 - binary_accuracy: 0.9846 - recall_3: 0.0000e+00 - precision_1: 0.0000e+00 - val_loss: 0.0796 - val_binary_accuracy: 0.9846 - val_recall_3: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 5/10\n",
      "7288/7288 [==============================] - 17s 2ms/step - loss: 0.0797 - binary_accuracy: 0.9846 - recall_3: 0.0000e+00 - precision_1: 0.0000e+00 - val_loss: 0.0796 - val_binary_accuracy: 0.9846 - val_recall_3: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 6/10\n",
      "7288/7288 [==============================] - 17s 2ms/step - loss: 0.0796 - binary_accuracy: 0.9846 - recall_3: 0.0000e+00 - precision_1: 0.0000e+00 - val_loss: 0.0796 - val_binary_accuracy: 0.9846 - val_recall_3: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 7/10\n",
      "7288/7288 [==============================] - 17s 2ms/step - loss: 0.0796 - binary_accuracy: 0.9846 - recall_3: 0.0000e+00 - precision_1: 0.0000e+00 - val_loss: 0.0796 - val_binary_accuracy: 0.9846 - val_recall_3: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 8/10\n",
      "7288/7288 [==============================] - 17s 2ms/step - loss: 0.0796 - binary_accuracy: 0.9846 - recall_3: 0.0000e+00 - precision_1: 0.0000e+00 - val_loss: 0.0796 - val_binary_accuracy: 0.9846 - val_recall_3: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 9/10\n",
      "7288/7288 [==============================] - 16s 2ms/step - loss: 0.0796 - binary_accuracy: 0.9846 - recall_3: 0.0000e+00 - precision_1: 0.0000e+00 - val_loss: 0.0796 - val_binary_accuracy: 0.9846 - val_recall_3: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 10/10\n",
      "7288/7288 [==============================] - 17s 2ms/step - loss: 0.0796 - binary_accuracy: 0.9846 - recall_3: 0.0000e+00 - precision_1: 0.0000e+00 - val_loss: 0.0796 - val_binary_accuracy: 0.9846 - val_recall_3: 0.0000e+00 - val_precision_1: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, \n",
    "                    validation_data=(x_val_scaled, y_val),\n",
    "                    epochs=10,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8503/8503 [==============================] - 7s 834us/step - loss: 0.0796 - binary_accuracy: 0.9846 - recall_3: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Test Accuracy: [0.07960547506809235, 0.9845888614654541, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8503/8503 [==============================] - 6s 671us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      1.00      0.99    267883\n",
      "        True       0.00      0.00      0.00      4193\n",
      "\n",
      "    accuracy                           0.98    272076\n",
      "   macro avg       0.49      0.50      0.50    272076\n",
      "weighted avg       0.97      0.98      0.98    272076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\brian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\brian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Detailed report of model to look at all metrics\n",
    "\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5\n",
      "Confusion Matrix:\n",
      "[[267883      0]\n",
      " [  4193      0]]\n"
     ]
    }
   ],
   "source": [
    "# ROC Curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "# Confusion Matrix\n",
    "threshold = 0.5 \n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Print metrics\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
